{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj96A/WyUc4pru+RST4VyA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KazDev17/Anime-Success-Predictor/blob/main/Anime_Rating_Predictor_v1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42SCRQtyOXuU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Project Introduction"
      ],
      "metadata": {
        "id": "DoENJD7DPDIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anime Success Predictor: Deep Learning Regression\n",
        "This project utilizes a dataset of over 14,000 anime entries to predict user ratings on MyAnimeList. Using a Deep Neural Network built with TensorFlow, we analyze metadata like Studios, Genres, Themes, and Source material to understand what drives high-rated content."
      ],
      "metadata": {
        "id": "xQp3HbFZO6Z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Cleaning & Safety\n"
      ],
      "metadata": {
        "id": "NfgnIXIZPZ8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Phase 2: Data Cleaning & Imputation\n",
        "To ensure model stability, I removed entries missing a 'Score' and perform Imputation on missing categorical data.\n",
        "\n",
        "By filling missing 'Themes' with \"None\", we retain 40% more data than a standard row-deletion approach."
      ],
      "metadata": {
        "id": "di3j64rEPH3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# df = pd.read_csv('mal_anime.csv')\n",
        "FILE_ID = '1qR68BPtRuQ6BRuv-uBoF5Eya9bn0P_Ws'\n",
        "data_url = f'https://drive.google.com/uc?export=download&id=1qR68BPtRuQ6BRuv-uBoF5Eya9bn0P_Ws'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(data_url)\n",
        "    print(f\"‚úÖ Dataset loaded successfully! Rows: {len(df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data: {e}\")\n",
        "    print(\"Check if the Google Drive link is set to 'Anyone with the link'.\")\n",
        "\n",
        "# Select features\n",
        "useful_columns = ['Type', 'Episodes', 'Source', 'Genres', 'Themes', 'Studios', 'Released_Year', 'Score']\n",
        "df_clean = df[useful_columns].copy()\n",
        "\n",
        "# Critical Cleaning\n",
        "df_clean = df_clean.dropna(subset=['Score']) # Remove rows without a target\n",
        "df_clean['Themes'] = df_clean['Themes'].fillna('None') # Impute missing themes\n",
        "df_clean['Episodes'] = pd.to_numeric(df_clean['Episodes'], errors='coerce').fillna(1)\n",
        "df_clean['Released_Year'] = df_clean['Released_Year'].fillna(df_clean['Released_Year'].median())\n",
        "df_clean = df_clean.dropna(subset=['Genres', 'Studios']) # Remove rows with no clues\n",
        "\n",
        "print(f\"Dataset Cleaned: {len(df_clean)} samples ready for training.\")"
      ],
      "metadata": {
        "id": "kQlFqTf0PUWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Feature Engineering"
      ],
      "metadata": {
        "id": "suFv8Bi8Pfpr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 3: Feature Engineering (One-Hot Encoding)\n",
        "\n",
        "Neural Networks require numerical input. I use One-Hot Encoding to transform categorical strings into a high-dimensional binary matrix. This results in nearly 1,000 unique features for the model to analyze."
      ],
      "metadata": {
        "id": "gMiP6m7IPjxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to binary features\n",
        "X = df_clean[['Released_Year', 'Episodes']].copy()\n",
        "X['Main_Type'] = df_clean['Type']\n",
        "X['Main_Source'] = df_clean['Source']\n",
        "X['Main_Genre'] = df_clean['Genres'].str.split(',').str[0]\n",
        "X['Main_Studio'] = df_clean['Studios'].str.split(',').str[0]\n",
        "X['Main_Theme'] = df_clean['Themes'].str.split(',').str[0]\n",
        "\n",
        "X = pd.get_dummies(X, columns=['Main_Type', 'Main_Source', 'Main_Genre', 'Main_Studio', 'Main_Theme'])\n",
        "y = df_clean['Score']\n",
        "\n",
        "# Split and Scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "yU88_ydqPvRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Training"
      ],
      "metadata": {
        "id": "_rxxZttZPyUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 4: Building the Neural Network\n",
        "\n",
        "We implement a 4-layer Sequential model.\n",
        "\n",
        "We include a Dropout layer (20%) to prevent overfitting, ensuring the model generalizes well to anime released in the future."
      ],
      "metadata": {
        "id": "hJCHlcJpPzmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "n9tA5SK0P4B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Results & Visualizations"
      ],
      "metadata": {
        "id": "jc-c-YmFQbGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 5: Performance Evaluation\n",
        "\n",
        "To evaluate the model, we plot the training and validation loss. \\\n",
        "\n",
        "This allows us to visualize the learning curve and identify if the model has successfully converged or if overfitting has occurred."
      ],
      "metadata": {
        "id": "572yUYpjQc2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up the plotting area\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Mean Absolute Error (Accuracy)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['mae'], label='Training MAE', color='#1f77b4', lw=2)\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE', color='#ff7f0e', lw=2)\n",
        "plt.title('Model Accuracy (MAE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error (MAL Points)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Loss (Mean Squared Error)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='#1f77b4', lw=2)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='#ff7f0e', lw=2)\n",
        "plt.title('Model Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss Score')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final Evaluation on the 20% \"Final Exam\" data\n",
        "final_results = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Final Test MAE: {final_results[1]:.4f}\")"
      ],
      "metadata": {
        "id": "-RBFp7o4Qidf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Interactive Prediction Demo"
      ],
      "metadata": {
        "id": "QYaX0jjOQo7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 6: Interactive \"What-If\" Analysis\n",
        "Use the interface below to test hypothetical anime configurations.\n",
        "\n",
        "This demo demonstrates the model's ability to perform Inference on user-provided data by mapping text inputs to the trained 995-feature vector."
      ],
      "metadata": {
        "id": "ugrrNQF0Qplt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. PREDICTION FUNCTION ---\n",
        "import numpy as np\n",
        "\n",
        "def predict_my_anime(type_name, source, genre, studio, theme, year, episodes):\n",
        "    # Create an empty row matching the training features\n",
        "    input_data = pd.DataFrame(np.zeros((1, X.shape[1])), columns=X.columns)\n",
        "\n",
        "    # Fill numeric data\n",
        "    input_data['Released_Year'] = year\n",
        "    input_data['Episodes'] = episodes\n",
        "\n",
        "    # Map categorical inputs to One-Hot columns\n",
        "    if f'Main_Type_{type_name}' in input_data.columns:\n",
        "        input_data[f'Main_Type_{type_name}'] = 1\n",
        "    if f'Main_Source_{source}' in input_data.columns:\n",
        "        input_data[f'Main_Source_{source}'] = 1\n",
        "    if f'Main_Genre_{genre}' in input_data.columns:\n",
        "        input_data[f'Main_Genre_{genre}'] = 1\n",
        "    if f'Main_Studio_{studio}' in input_data.columns:\n",
        "        input_data[f'Main_Studio_{studio}'] = 1\n",
        "    if f'Main_Theme_{theme}' in input_data.columns:\n",
        "        input_data[f'Main_Theme_{theme}'] = 1\n",
        "\n",
        "    # Scale the input using the same parameters as the training data\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(input_scaled, verbose=0)\n",
        "    return prediction[0][0]\n",
        "\n",
        "# --- 2. INTERACTIVE UI ---\n",
        "# @title üì∫ Ultimate Anime Score Predictor\n",
        "# Fill these out to test your most niche anime ideas!\n",
        "\n",
        "Type = \"TV\" # @param [\"TV\", \"Movie\", \"OVA\", \"ONA\", \"Special\", \"Music\"]\n",
        "Source = \"Manga\" # @param [\"Manga\", \"Original\", \"Light Novel\", \"Visual Novel\", \"Web manga\", \"Novel\", \"Game\", \"Other\"]\n",
        "Genre = \"Fantasy\" # @param [\"Action\", \"Adventure\", \"Avant Garde\", \"Award Winning\", \"Boys Love\", \"Comedy\", \"Drama\", \"Ecchi\", \"Erotica\", \"Fantasy\", \"Girls Love\", \"Gourmet\", \"Horror\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Slice of Life\", \"Sports\", \"Supernatural\", \"Suspense\"]\n",
        "Theme = \"Isekai\" # @param [\"Adult Cast\", \"Anthropomorphic\", \"CGDCT\", \"Childcare\", \"Combat Sports\", \"Detective\", \"Educational\", \"Gore\", \"Harem\", \"High Stakes Game\", \"Historical\", \"Idols (Female)\", \"Idols (Male)\", \"Isekai\", \"Iyashikei\", \"Love Polygon\", \"Magical Sex Shift\", \"Mahou Shoujo\", \"Martial Arts\", \"Mecha\", \"Medical\", \"Military\", \"Music\", \"Mythology\", \"Organized Crime\", \"Otaku Culture\", \"Parody\", \"Performing Arts\", \"Pets\", \"Psychological\", \"Racing\", \"Reincarnation\", \"Reverse Harem\", \"Romantic Subtext\", \"Samurai\", \"School\", \"Showbiz\", \"Space\", \"Strategy Game\", \"Super Power\", \"Survival\", \"Team Sports\", \"Time Travel\", \"Vampires\", \"Video Game\", \"Visual Arts\", \"Workplace\", \"None\"]\n",
        "Studio = \"TMS Entertainment\" # @param [\"Madhouse\", \"Sunrise\", \"Toei Animation\", \"Bones\", \"MAPPA\", \"A-1 Pictures\", \"Ufotable\", \"Kyoto Animation\", \"Wit Studio\", \"Shaft\", \"Production I.G\", \"J.C.Staff\", \"Studio Pierrot\", \"TMS Entertainment\", \"Studio Ghibli\", \"Shin-Ei Animation\"]\n",
        "Year = 2026 # @param {type:\"slider\", min:1960, max:2030, step:1}\n",
        "Episodes = 24 # @param {type:\"number\"}\n",
        "\n",
        "# Run the prediction using the function we built earlier\n",
        "score = predict_my_anime(Type, Source, Genre, Studio, Theme, Year, Episodes)\n",
        "\n",
        "print(f\"--- PREDICTION RESULT ---\")\n",
        "print(f\"Type: {Type} | Source: {Source} | Studio: {Studio}\")\n",
        "print(f\"Genre: {Genre} | Theme: {Theme}\")\n",
        "print(f\"Year: {Year} | Episodes: {Episodes}\")\n",
        "print(f\"\\nPredicted MAL Score: {score:.2f}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iXm9GvupQuMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion"
      ],
      "metadata": {
        "id": "chBHt39YRGO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion & Key Learnings\n",
        "\n",
        "\n",
        "*   **Model Performance**: The model predicts anime scores with an average error of **0.48 points**\n",
        "\n",
        "*   **Non-Linear Relationships**: I chose a Neural Network over a standard Linear Regression because the factors affecting anime popularity (like Studio reputation vs. Genre trends) are non-linear and complex.\n",
        "\n",
        "\n",
        "*   **Feature Engineering**: One-Hot Encoding proved essential, turning categorical metadata into a 995-feature vector that the model could mathematically process.\n",
        "\n",
        "*   **Future Improvements**: Adding user-review sentiment analysis or budget data could further refine the model's accuracy."
      ],
      "metadata": {
        "id": "0o3yWevlRM4Z"
      }
    }
  ]
}